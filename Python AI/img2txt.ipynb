{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"img2txt.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"1Rfcl0-6y8UDxan5k_M7dechaNaErrQq8","authorship_tag":"ABX9TyOk9epfsSbOS1cknetdCJw5"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":2,"metadata":{"id":"TrhXeDOn3oSI","executionInfo":{"status":"ok","timestamp":1656481299196,"user_tz":-540,"elapsed":3098,"user":{"displayName":"48","userId":"17678505092892983243"}}},"outputs":[],"source":["import os\n","import re\n","import numpy as np\n","import matplotlib.pyplot as plt\n","\n","import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow.keras import layers\n","from tensorflow.keras.applications import efficientnet\n","from tensorflow.keras.layers import TextVectorization"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xxtkHWu4Gdfd","executionInfo":{"status":"ok","timestamp":1656482963124,"user_tz":-540,"elapsed":7901,"user":{"displayName":"48","userId":"17678505092892983243"}},"outputId":"5d080282-1432-409f-f370-2625a48d81d5"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","source":["cd /content/drive/MyDrive/data"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aYP2mwrj4r3f","executionInfo":{"status":"ok","timestamp":1656482964550,"user_tz":-540,"elapsed":283,"user":{"displayName":"48","userId":"17678505092892983243"}},"outputId":"058b3646-1640-4b7c-f8c5-92e20947b1e4"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/data\n"]}]},{"cell_type":"code","source":["!ls"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6Abb2HwjGk7o","executionInfo":{"status":"ok","timestamp":1656482965707,"user_tz":-540,"elapsed":5,"user":{"displayName":"48","userId":"17678505092892983243"}},"outputId":"802bfa82-15ab-4baa-ba64-b07f29806352"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["CrowdFlowerAnnotations.txt  Flickr_8k.devImages.txt   Flickr8k.token.txt\n","ExpertAnnotations.txt\t    Flickr8k.lemma.token.txt  Flickr_8k.trainImages.txt\n","Flicker8k_Dataset\t    Flickr_8k.testImages.txt  __MACOSX\n","Flickr8k_Dataset.zip\t    Flickr8k_text.zip\t      readme.txt\n"]}]},{"cell_type":"code","source":["# !unzip Flickr8k_Dataset.zip\n","# !unzip Flickr8k_text.zip"],"metadata":{"id":"d0I4fQoeGn_1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["seed = 111\n","np.random.seed(seed)\n","tf.random.set_seed(seed)"],"metadata":{"id":"3e5ezV4V4r6I","executionInfo":{"status":"ok","timestamp":1656482967171,"user_tz":-540,"elapsed":252,"user":{"displayName":"48","userId":"17678505092892983243"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["IMAGES_PATH = \"/content/drive/MyDrive/data/Flicker8k_Dataset\"\n","\n","IMAGE_SIZE = (299, 299)\n","\n","VOCAB_SIZE = 10000\n","\n","SEQ_LENGTH = 25\n","\n","EMBED_DIM = 512\n","\n","FF_DIM = 512\n","\n","BATCH_SIZE = 64\n","EPOCHS = 30\n","AUTOTUNE = tf.data.AUTOTUNE"],"metadata":{"id":"5N9r8Jfj45U3","executionInfo":{"status":"ok","timestamp":1656482968393,"user_tz":-540,"elapsed":1,"user":{"displayName":"48","userId":"17678505092892983243"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":["def load_caption_data(filename):\n","  with open(filename) as caption_file:\n","    caption_data = caption_file.readlines()\n","    caption_mapping = {}\n","    text_data = []\n","    images_to_skip = set()\n","\n","    for line in caption_data:\n","      line = line.rstrip(\"\\n\")\n","      img_name, caption = line.split(\"\\t\")\n","\n","      img_name = img_name.split(\"#\")[0]\n","      img_name = os.path.join(IMAGES_PATH, img_name.strip())\n","\n","      tokens = caption.strip().split()\n","\n","      if len(tokens) < 5 or len(tokens) > SEQ_LENGTH:\n","        images_to_skip.add(img_name)\n","        continue\n","\n","      if img_name.endswith(\"jpg\") and img_name not in images_to_skip:\n","        caption = \"<start> \" + caption.strip() + \" <end>\"\n","        text_data.append(caption)\n","\n","      if img_name in caption_mapping:\n","        caption_mapping[img_name].append(caption)\n","      else:\n","        caption_mapping[img_name] = [caption]\n","\n","    for img_name in images_to_skip:\n","      if img_name in caption_mapping:\n","        del caption_mapping[img_name]\n","\n","    return caption_mapping, text_data"],"metadata":{"id":"7YGi5nWX4r83","executionInfo":{"status":"ok","timestamp":1656482969724,"user_tz":-540,"elapsed":305,"user":{"displayName":"48","userId":"17678505092892983243"}}},"execution_count":14,"outputs":[]},{"cell_type":"code","source":["def train_val_split(caption_data, train_size=0.8, shuffle=True):\n","  all_images = list(caption_data.keys())\n","\n","  if shuffle:\n","    np.random.shuffle(all_images)\n","\n","  train_size = int(len(caption_data) * train_size)\n","\n","  training_data = {\n","      img_name: caption_data[img_name] for img_name in all_images[:train_size]\n","  }\n","  validation_data = {\n","      img_name: caption_data[img_name] for img_name in all_images[train_size:]\n","  }\n","\n","  return training_data, validation_data"],"metadata":{"id":"aAlU3EFh4r_7","executionInfo":{"status":"ok","timestamp":1656482971949,"user_tz":-540,"elapsed":256,"user":{"displayName":"48","userId":"17678505092892983243"}}},"execution_count":15,"outputs":[]},{"cell_type":"code","source":["captions_mapping, text_data = load_caption_data('/content/drive/MyDrive/data/Flickr8k.token.txt')"],"metadata":{"id":"FzeAGvZZ4sC0","executionInfo":{"status":"ok","timestamp":1656482974928,"user_tz":-540,"elapsed":734,"user":{"displayName":"48","userId":"17678505092892983243"}}},"execution_count":16,"outputs":[]},{"cell_type":"code","source":["train_data, valid_data = train_val_split(captions_mapping)\n","print(\"Number of training samples: \", len(train_data))\n","print(\"Number of validation samples: \", len(valid_data))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0jXh9RmVsNeC","executionInfo":{"status":"ok","timestamp":1656482976850,"user_tz":-540,"elapsed":277,"user":{"displayName":"48","userId":"17678505092892983243"}},"outputId":"add18716-5a03-4861-9588-19b3b6a4dc13"},"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["Number of training samples:  6115\n","Number of validation samples:  1529\n"]}]},{"cell_type":"code","source":["def custom_standardization(input_string):\n","  lowercase = tf.strings.lower(input_string)\n","  return tf.strings.regex_replace(lowercase, \"[%s]\" % re.escape(strip_chars), \"\")"],"metadata":{"id":"wDKxDUmXsNgl","executionInfo":{"status":"ok","timestamp":1656482979059,"user_tz":-540,"elapsed":259,"user":{"displayName":"48","userId":"17678505092892983243"}}},"execution_count":18,"outputs":[]},{"cell_type":"code","source":["strip_chars = \"!\\\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\"\n","strip_chars = strip_chars.replace(\"<\", \"\")\n","strip_chars = strip_chars.replace(\">\", \"\")\n","\n","vectorization = TextVectorization(\n","    max_tokens = VOCAB_SIZE,\n","    output_mode = \"int\",\n","    output_sequence_length = SEQ_LENGTH,\n","    standardize = custom_standardization,\n",")\n","vectorization.adapt(text_data)\n","\n","image_augmentation = keras.Sequential(\n","    [\n","     layers.RandomFlip(\"horizontal\"),\n","     layers.RandomRotation(0.2),\n","     layers.RandomContrast(0.3),\n","    ]\n",")"],"metadata":{"id":"R0x19ngysNja","executionInfo":{"status":"ok","timestamp":1656482983187,"user_tz":-540,"elapsed":2262,"user":{"displayName":"48","userId":"17678505092892983243"}}},"execution_count":19,"outputs":[]},{"cell_type":"code","source":["def decode_and_resize(img_path):\n","  img = tf.io.read_file(img_path)\n","  img = tf.image.decode_jpeg(img, channels=3)\n","  img = tf.image.resize(img, IMAGE_SIZE)\n","  img = tf.image.convert_image_dtype(img, tf.float32)\n","\n","def process_input(img_path, captions):\n","  return decode_and_resize(img_path), vectorization(captions)\n","\n","def make_dataset(images, captions):\n","  if split == \"train\":  # ????????????????????????\n","    img_dataset = tf.data.Dataset.from_tensor_slices(images).map(\n","        read_train_image, num_parallel_calls = AUTOTUNE # ????????????????????????\n","    )\n","  else:\n","    img_dataset = tf.data.Dataset.from_tensor_slices(images).map(\n","        read_valid_image, num_parallel_calls = AUTOTUNE # ????????????????????????\n","    )\n","  cap_dataset = tf.data.Dataset.from_tensor_slices(captions).map(\n","      vectorization, num_parallel_calls = AUTOTUNE\n","  )\n","\n","  dataset = tf.data.Dataset.zip((img_dataset, cap_dataset))\n","  dataset = dataset.batch(BATCH_SIZE).shuffle(256).prefetch(AUTOTUNE)\n","  return dataset"],"metadata":{"id":"iCeTlEpNsNnm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_dataset = make_dataset(list(train_data.keys()), list(train_data.values()))\n","\n","valid_dataset = make_dataset(list(valid_data.keys()), list(valid_data.values()))"],"metadata":{"id":"HZeEc3kh4sFa"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def get_cnn_model():\n","  base_model = efficientnet.EfficientNetB0(\n","      input_shape=(*IMAGE_SIZE, 3), include_top=False, weights=\"imagenet\",\n","  )\n","  base_model.trainable = False\n","  base_model_out = base_model.output\n","  base_model_out = layers.Reshape((-1, base_model_out.shape[-1]))(base_model_out)\n","  cnn_model = keras.model.Model(base_model.input, base_model_out)\n","  return cnn_model"],"metadata":{"id":"hhFBaNUP4sHy","executionInfo":{"status":"ok","timestamp":1656482996704,"user_tz":-540,"elapsed":285,"user":{"displayName":"48","userId":"17678505092892983243"}}},"execution_count":20,"outputs":[]},{"cell_type":"code","source":["class TransformerEncoderBlock(layers.Layer):\n","  def __init__(self, embed_dim, dense_dim, num_heads, **kwargs):\n","    super().__init__(**kwargs)\n","    self.embed_dim = embed_dim\n","    self.dense_dim = dense_dim\n","    self.num_heads = num_heads\n","    self.attention_1 = layers.MultiHeadAttention(\n","        num_heads=num_heads, key_dim=embed_dim, dropout=0.0\n","        )\n","    self.layernorm_1 = layers.LayerNormalization()\n","    self.layernorm_2 = layers.LayerNormalization()\n","    self.dense_1 = layers.Dense(embed_dim, activation=\"relu\")\n","\n","  def call(self, inputs, training, mask=None):\n","    inputs = self.layernorm_1(inputs)\n","    inputs = self.dense_1(inputs)\n","    \n","    atttention_output_1 = self.attention_1(\n","        query=inputs,\n","        value = inputs,\n","        key = inputs,\n","        attention_mask = None,\n","        training = training,\n","    ) # ????????????????????????\n","\n","    out_1 = self.layernorm_2(inputs + atttention_output_1)\n","    return out_1"],"metadata":{"id":"qYv5EPSgxb3H","executionInfo":{"status":"ok","timestamp":1656482998734,"user_tz":-540,"elapsed":459,"user":{"displayName":"48","userId":"17678505092892983243"}}},"execution_count":21,"outputs":[]},{"cell_type":"code","source":["class PositionalEmbedding(layers.Layer):\n","  def __init__(self, sequence_length, vocab_size, embed_dim, **kwargs):\n","    super().__init__(**kwargs)\n","    self.token_embeddings = layers.Embedding(\n","        input_dim=vocab_size, output_dim=embed_dim\n","    )\n","    self.position_embeddings = layers.Embedding(\n","        input_dim=sequence_length, output_dim=embed_dim\n","    )\n","    self.sequence_length = sequence_length\n","    self.vocab_size = vocab_size\n","    self.embed_dim = embed_dim\n","    self.embed_scale = tf.math.sqrt(tf.cast(embed_dim, tf.float32))\n","\n","  def call(self, inputs): # ????????????????????????\n","    length = tf.shape(inputs)[-1]\n","    positions = tf.range(strat=0, limit=length, delta=1)\n","    embedded_tokens = self.token_embeddings(inputs)\n","    embedded_tokens = embedded_tokens * self.embed_scale\n","    embedded_positions = self.position_embeddings(positions)\n","    return embedded_tokens + embedded_positions\n","\n","  def compute_mask(self, inputs, mask=None):\n","    return tf.math.not_equal(inputs, 0)"],"metadata":{"id":"FL2jPBUXxb5d","executionInfo":{"status":"ok","timestamp":1656483001666,"user_tz":-540,"elapsed":364,"user":{"displayName":"48","userId":"17678505092892983243"}}},"execution_count":22,"outputs":[]},{"cell_type":"code","source":["class TransformerDecoderBlock(layers.Layer):\n","  def __init__(self, embed_dim, ff_dim, num_heads, **kwargs):\n","    super().__init__(**kwargs)\n","    self.embed_dim = embed_dim\n","    self.ff_dim = ff_dim\n","    self.num_heads = num_heads\n","    self.attention_1 = layers.MultiHeadAttention(\n","        num_heads=num_heads, key_dim=embed_dim, dropout=0.1\n","    )\n","    self.attention_2 = layers.MultiHeadAttention(\n","        num_heads=num_heads, key_dim=embed_dim, dropout=0.1\n","    )\n","    self.ffn_layer_1 = layers.Dense(ff_dim, activation=\"relu\")\n","    self.ffn_layer_2 = layers.Dense(embed_dim)\n","\n","    self.layernorm_1 = layers.LayerNormalization()\n","    self.layernorm_2 = layers.LayerNormalization()\n","    self.layernorm_3 = layers.LayerNormalization()\n","\n","    self.embedding = PositionalEmbedding(\n","        embed_dim=EMBED_DIM, sequence_length=SEQ_LENGTH, vocab_size=VOCAB_SIZE\n","    )\n","    self.out = layers.Dense(VOCAB_SIZE, activation=\"softmax\")\n","\n","    self.dropout_1 = layers.Dropout(0.3)\n","    self.dropout_2 = layers.Dropout(0.5)\n","    self.supports_masking = True\n","\n","  def call(self, inputs, encoder_outputs, training, mask=None):\n","    inputs = self.embedding(inputs)\n","    casual_mask = self.get_casual_attention_mask(inputs)\n","\n","    if mask is not None:\n","      padding_mask = tf.cast(mask[:,:,tf.newaxis], dtype=tf.int32)\n","      combined_mask = tf.cast(mask[:, tf.newaxis], dtype=tf.int32)\n","      combined_mask = tf.minimum(combined_mask, casual_mask)\n","\n","    atttention_output_1 = self.attention_1(\n","        query=inputs,\n","        value = inputs,\n","        key = inputs,\n","        attention_mask = combined_mask,\n","        training = training,\n","    )\n","    out_1 = self.layernorm_1(inputs + atttention_output_1)\n","\n","    atttention_output_2 = self.attention_2(\n","        query=out_1,\n","        value = encoder_outputs,\n","        key = encoder_outputs,\n","        attention_mask = padding_mask,\n","        training = training,\n","    )\n","    out_2 = self.layernorm_2(out_1 + atttention_output_2)\n","\n","    ffn_out = self.ffn_layer_1(out_2)\n","    ffn_out = self.dropout_1(ffn_out, training=training)\n","    ffn_out = self.ffn_layer_2(ffn_out)\n","\n","    ffn_out = self.layernorm_3(ffn_out + out_2, training=training)\n","    ffn_out = self.dropout_2(ffn_out, training=training)\n","    preds = self.out(ffn_out)\n","    return preds\n","\n","  def get_casual_attention_mask(self, inputs):\n","    input_shape = tf.shape(inputs)\n","    batch_size, sequence_length = input_shape[0], input_shape[1]\n","    i = tf.range(sequence_length)[:, tf.newaxis]\n","    j = tf.range(sequence_length)\n","    mask = tf.cast(i >= j, dtype=\"int32\")\n","    mask = tf.reshape(mask, (1, input_shape[1], input_shape[1]))\n","    mult = tf.concat(\n","        [tf.expand_dims(batch_size, -1), tf.constant([1, 1], dtype=tf.int32)],\n","         axis=0,)\n","    return tf.tile(mask, mult)"],"metadata":{"id":"15Nk6KOoxb8G","executionInfo":{"status":"ok","timestamp":1656483011167,"user_tz":-540,"elapsed":252,"user":{"displayName":"48","userId":"17678505092892983243"}}},"execution_count":24,"outputs":[]},{"cell_type":"code","source":["class ImageCaptioningModel(keras.Model):\n","  def __init__(\n","    self, cnn_model, encoder, decoder, num_captions_per_image=5, image_aug=None,):\n","    super().__init__()\n","    self.cnn_model = cnn_model\n","    self.encoder = encoder\n","    self.decoder = decoder\n","    self.loss_tracker = keras.metrics.Mean(name=\"loss\")\n","    self.acc_tracker = keras.metrics.Mean(name=\"accuracy\")\n","    self.num_captions_per_image = num_captions_per_image\n","    self.image_aug = image_aug\n","\n","  def calculate_loss(self, y_true, y_pred, mask):\n","    loss = self.loss(y_true, y_pred)\n","    mask = tf.cast(mask, dtype=loss.dtype)\n","    loss *= mask\n","    return tf.reduce_sum(loss) / tf.reduce_sum(mask)\n","\n","  def calculate_accuracy(self, y_true, y_pred, mask):\n","    accuracy = tf.equal(y_true, tf.argmax(y_pred, axis=2))\n","    accuracy = tf.math.logical_and(mask, accuracy)\n","    accuracy = tf.cast(accuracy, dtype=tf.float32)\n","    mask = tf.cast(mask, dtype=tf.float32)\n","    return tf.reduce_sum(accuracy) / tf.reduce_sum(mask)\n","  \n","  def _compute_caption_loss_and_acc(self, img_embed, batch_seq, training=True):\n","    encoder_out = self.encoder(img_embed, training=training)\n","    batch_seq_inp = batch_seq[:, :-1]\n","    batch_seq_true = batch_seq[:, 1:]\n","    mask = tf.math.not_equal(batch_seq_true, 0)\n","    batch_seq_pred = self.decoder(\n","        batch_seq_inp, encoder_out, training = training, mask=mask\n","    )\n","    loss = self.calculate_loss(batch_seq_true, batch_seq_pred, mask)\n","    acc = self.calculate_accuracy(batch_seq_true, batch_seq_pred, mask)\n","    return loss, acc # ??????????????\n","\n","  def train_step(self, batch_data):\n","    batch_img, batch_seq = batch_data\n","    batch_loss = 0\n","    batch_acc = 0\n","\n","    if self.image_aug:\n","      batch_img = self.image_aug(batch_img)\n","\n","    img_embed = self.cnn_model(batch_img)\n","\n","    for i in range(self.num_captions_per_image):\n","      with tf.GradientTape() as tape:\n","        loss, acc = self._compute_caption_loss_and_acc(\n","            img_embed, batch_seq[:, i, :], training=True\n","        )\n","\n","        batch_loss += loss\n","        batch_acc += acc\n","\n","      train_vars = (\n","          self.encoder.trainable_variables + self.decoder.trainable_variables\n","      )\n","\n","      grads = tape.gradient(loss, train_vars)\n","\n","      self.optimizer.apply_gradients(zip(grads, train_vars))\n","\n","      batch_acc /= float(self.num_captions_per_image)\n","      self.loss_tracker.update_state(batch_loss)\n","      self.acc_tracker.update_state(batch_acc)\n","\n","      return {\"loss\": self.loss_tracker.result(), \"acc\": self.acc_tracker.result()}\n","  # ???????????????\n","  def test_step(self, batch_data):\n","    batch_img, batch_seq = batch_data\n","    batch_loss = 0\n","    batch_acc = 0\n","\n","    img_embed = self.cnn_model(batch_img)\n","\n","    for i in range(self.num_captions_per_image):\n","      loss, acc = self._compute_caption_loss_and_acc(\n","          img_embed, batch_seq[:, i, :], training=False\n","      )\n","\n","      batch_loss += loss\n","      batch_acc += acc\n","\n","    batch_acc /= float(self.num_captions_per_image)\n","\n","    self.loss_tracker.update_state(batch_loss)\n","    self.acc_tracker.update_state(batch_acc)\n","\n","    return {\"loss\": self.loss_tracker.result(), \"acc\": self.acc_tracker.result()}\n","\n","  @property\n","  def metrics(self):\n","    return [self.loss_tracker, self.acc_tracker]"],"metadata":{"id":"q6As6g73uej9","executionInfo":{"status":"ok","timestamp":1656483014775,"user_tz":-540,"elapsed":267,"user":{"displayName":"48","userId":"17678505092892983243"}}},"execution_count":25,"outputs":[]},{"cell_type":"code","source":["cnn_model = get_cnn_model()\n","encoder = TransformerEncoderBlock(embed_dim=EMBED_DIM, dense_dim=FF_DIM, num_heads=1)\n","decoder = TransformerDecoderBlock(embed_dim=EMBED_DIM, dense_dim=FF_DIM, num_heads=2)\n","caption_model = ImageCaptioningModel(\n","    cnn_model=cnn_model, encoder=encoder, decoder=decoder, image_aug=image_augmentation,\n",")"],"metadata":{"id":"HDdVk0bQ-vnZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["cross_entropy = keras.losses.SparseCategoricalCrossentropy(\n","    from_logits=False, reduction=\"none\"\n",")\n","\n","early_stopping = keras.callbacks.EarlyStopping(patience=3, restore_best_weights=True)"],"metadata":{"id":"Y8oqsk8j_S4U","executionInfo":{"status":"ok","timestamp":1656483025675,"user_tz":-540,"elapsed":289,"user":{"displayName":"48","userId":"17678505092892983243"}}},"execution_count":27,"outputs":[]},{"cell_type":"code","source":["# ??????????????????????????\n","class LRSchedule(keras.optimizers.schedules.LearningRateSchedule):\n","  def __init__(self, post_warmup_learning_rate, warmup_steps):\n","    super().__init__()\n","    self.post_warmup_learning_rate = post_warmup_learning_rate\n","    self.warmup_steps = warmup_steps\n","\n","  def __call__(self, step):\n","    global_step = tf.cast(step, tf.float32)\n","    warmup_steps = tf.cast(self.warmup_steps, tf.float32)\n","    warmup_progress = global_step / warmup_steps\n","    warmup_learning_rate = self.post_warmup_learning_rate * warmup_progress\n","    return tf.cond(\n","        global_step < warmup_steps,\n","        lambda: warmup_learning_rate,\n","        lambda: self.post_warmup_laerning_rate,\n","    )"],"metadata":{"id":"lPK5qZvU_s7b","executionInfo":{"status":"ok","timestamp":1656483026738,"user_tz":-540,"elapsed":1,"user":{"displayName":"48","userId":"17678505092892983243"}}},"execution_count":28,"outputs":[]},{"cell_type":"code","source":["num_train_steps = len(train_dataset) * EPOCHS\n","num_warmup_steps = num_train_steps // 15\n","lr_schedule = LRSchedule(post_warmup_learning_rate=1e-4, warmup_steps=num_warmup_steps)\n","\n","captional_model.compile(optimizer=keras.optimizers.Adam(lr_schedule), loss=cross_entropy)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":281},"id":"dmsAfwPLCnnS","executionInfo":{"status":"error","timestamp":1656483033860,"user_tz":-540,"elapsed":699,"user":{"displayName":"48","userId":"17678505092892983243"}},"outputId":"7ec261c1-da90-4d0b-b545-33a9abcc4781"},"execution_count":29,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-29-f589eabb98b3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnum_train_steps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mEPOCHS\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mnum_warmup_steps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnum_train_steps\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0;36m15\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mlr_schedule\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLRSchedule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpost_warmup_learning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwarmup_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_warmup_steps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mcaptional_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlr_schedule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcross_entropy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'train_dataset' is not defined"]}]},{"cell_type":"code","source":["captional_model.summary()"],"metadata":{"id":"SwiUtj1BDxTc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["caption_model.fit(\n","    train_dataset,\n","    epochs=EPOCHS,\n","    validation_data=valid_dataset,\n","    callbacks=[early_stopping]\n",")"],"metadata":{"id":"aOEb1dWND4y5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["vocab = vectorization.get_vocabulary()\n","index_lookup = dict(zip(range(len(vocab)), vocab))\n","max_decoded_sequence_length = SEQ_LENGTH - 1\n","valid_images = list(valid_data.keys())"],"metadata":{"id":"eR5zQqhVEHc9","executionInfo":{"status":"ok","timestamp":1656483040368,"user_tz":-540,"elapsed":268,"user":{"displayName":"48","userId":"17678505092892983243"}}},"execution_count":30,"outputs":[]},{"cell_type":"code","source":["def generate_caption():\n","  sample_img = np.random.choice(valid_images)\n","\n","  sample_img = decode_and_resize(sample_img)\n","  img = sample_img.numpy().clip(0, 255).astype(np.uint8)\n","  plt.inshow(img)\n","  plt.show()\n","\n","  img = tf.expand_dims(sample_img, 0)\n","  img = captional_model.cnn_model(img)\n","\n","  encoded_img = captional_model.encoder(ing, training=False)\n","\n","  decoded_caption = \"<start> \"\n","  for i in range(max_decoded_sequence_length):\n","    tokenized_caption = vectorization([decoded_caption])[:, :-1]\n","    mask = tf.math.not_equal(tokenized_caption, 0)\n","    predictions = caption_model.decoder(\n","        tokenized_caption, encoded_img, training=False, mask=mask\n","    )\n","    sampled_token_index = np.argmax(predictions[0, i, :])\n","    sampled_token = index_lookup[sampled_token_index]\n","    if sampled_token == \" <end>\":\n","      break\n","    decoded_caption += \" \" + sampled_token\n","\n","  decoded_caption = decoded_caption.replace(\"<start> \", \"\")\n","  decoded_caption = decoded_caption.replace(\" <end>\", \"\").strip()\n","  print(\"Predicted Caption: \", decoded_caption)\n","\n","generate_caption()\n","generate_caption()\n","generate_caption()"],"metadata":{"id":"GbtXLdWSFgYP","executionInfo":{"status":"ok","timestamp":1656483736140,"user_tz":-540,"elapsed":280,"user":{"displayName":"48","userId":"17678505092892983243"}}},"execution_count":35,"outputs":[]}]}