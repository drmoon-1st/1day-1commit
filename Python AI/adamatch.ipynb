{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"adamatch.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyOJTSYZF6Vfo3USv2xUvnoV"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"easqifpo1uIC","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1657556101010,"user_tz":-540,"elapsed":107914,"user":{"displayName":"48","userId":"17678505092892983243"}},"outputId":"6eef495f-5737-47c2-8cc6-76e6750e9768"},"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[K     |████████████████████████████████| 2.1 MB 8.9 MB/s \n","\u001b[K     |████████████████████████████████| 48.3 MB 1.8 MB/s \n","\u001b[33mWARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ProtocolError('Connection aborted.', ConnectionResetError(104, 'Connection reset by peer'))': /simple/tensorflow-model-optimization/\u001b[0m\n","\u001b[K     |████████████████████████████████| 237 kB 48.0 MB/s \n","\u001b[K     |████████████████████████████████| 636 kB 46.5 MB/s \n","\u001b[K     |████████████████████████████████| 99 kB 7.2 MB/s \n","\u001b[K     |████████████████████████████████| 92 kB 9.6 MB/s \n","\u001b[K     |████████████████████████████████| 1.1 MB 50.1 MB/s \n","\u001b[K     |████████████████████████████████| 1.2 MB 46.7 MB/s \n","\u001b[K     |████████████████████████████████| 352 kB 49.6 MB/s \n","\u001b[K     |████████████████████████████████| 43 kB 1.0 MB/s \n","\u001b[K     |████████████████████████████████| 511.7 MB 4.8 kB/s \n","\u001b[K     |████████████████████████████████| 4.6 MB 39.7 MB/s \n","\u001b[K     |████████████████████████████████| 1.6 MB 37.8 MB/s \n","\u001b[K     |████████████████████████████████| 438 kB 44.3 MB/s \n","\u001b[K     |████████████████████████████████| 5.8 MB 38.1 MB/s \n","\u001b[?25h  Building wheel for py-cpuinfo (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n"]}],"source":["!pip install -q tf-models-official"]},{"cell_type":"code","source":["import tensorflow as tf\n","\n","tf.random.set_seed(42)\n","\n","import numpy as np\n","\n","from tensorflow import keras\n","from tensorflow.keras import layers\n","from tensorflow.keras import regularizers\n","# from official.vision.image_classification.augment import RandAugment\n","\n","import tensorflow_datasets as tfds\n","\n","tfds.disable_progress_bar()"],"metadata":{"id":"JoX7HJlakx68","executionInfo":{"status":"ok","timestamp":1657581643793,"user_tz":-540,"elapsed":2359,"user":{"displayName":"48","userId":"17678505092892983243"}}},"execution_count":1,"outputs":[]},{"cell_type":"code","source":["(mnist_x_train, mnist_y_train), (mnist_x_test, mnist_y_test) = keras.datasets.mnist.load_data()\n","\n","mnist_x_train = tf.expand_dims(mnist_x_train, -1)\n","mnist_x_test = tf.expand_dims(mnist_x_test, -1)\n","\n","mnist_y_train = tf.one_hot(mnist_y_train, 10).numpy()\n","\n","svhn_train, svhn_test = tfds.load(\n","    \"svhn_cropped\", split=[\"train\", \"test\"], as_supervised=True\n",")"],"metadata":{"id":"Yy87NlQPEhTX","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1657582147753,"user_tz":-540,"elapsed":498358,"user":{"displayName":"48","userId":"17678505092892983243"}},"outputId":"0e65c621-f68c-4eda-ab4e-3be113cbc7b0"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n","11493376/11490434 [==============================] - 0s 0us/step\n","11501568/11490434 [==============================] - 0s 0us/step\n","\u001b[1mDownloading and preparing dataset svhn_cropped/3.0.0 (download: 1.47 GiB, generated: Unknown size, total: 1.47 GiB) to /root/tensorflow_datasets/svhn_cropped/3.0.0...\u001b[0m\n","Shuffling and writing examples to /root/tensorflow_datasets/svhn_cropped/3.0.0.incomplete4A7YTY/svhn_cropped-train.tfrecord\n","Shuffling and writing examples to /root/tensorflow_datasets/svhn_cropped/3.0.0.incomplete4A7YTY/svhn_cropped-test.tfrecord\n","Shuffling and writing examples to /root/tensorflow_datasets/svhn_cropped/3.0.0.incomplete4A7YTY/svhn_cropped-extra.tfrecord\n","\u001b[1mDataset svhn_cropped downloaded and prepared to /root/tensorflow_datasets/svhn_cropped/3.0.0. Subsequent calls will reuse this data.\u001b[0m\n"]}]},{"cell_type":"code","source":["RESIZE_TO = 32\n","SOURCE_BATCH_SIZE = 64\n","TARGET_BATCH_SIZE = 3\n","EPOCHS = 10\n","STEPS_PER_EPOCH"],"metadata":{"id":"f08sE1j9kLvH"},"execution_count":null,"outputs":[]}]}